Below is your full text rewritten into **clean, properly formatted Markdown**, with **no content changes** â€” only structure, spacing, and formatting fixes.

---

# âš¡ ML-UEBA â€” Machine Learning User & Entity Behavior Analytics

ML-UEBA is a modular, high-performance log analytics and anomaly-detection framework built for:

* Security Operations (SOC)
* Threat Detection
* UEBA (User & Entity Behavior Analytics)
* SIEM enrichment
* Distributed log ingestion environments

The project provides a full pipeline:

```
Raw Logs â†’ Parsing â†’ Normalization â†’ NLP Enrichment â†’ Feature Engineering â†’ Embeddings â†’ ML/Anomaly Detection
```
## Architecture Overview

<p align="center">
  <img src="arc.svg" alt="ML-UEBA Architecture" width="900"/>
</p>

---

# ğŸš€ Features

### âœ… Multi-source Log Parsing

Automatically identifies & parses logs from:

* **Linux Syslog**
* **Windows Event Logs**
* **Windows PowerShell**
* **macOS Unified Logs**
* **SSHD logs**
* **RDP logs**
* **PAM logs**
* **Active Directory / Kerberos**
* **CloudTrail**
* **CloudWatch**
* **AWS VPC Flow Logs**
* **GuardDuty**
* **Azure Activity / Firewall / AD Logs**
* **GCP Audit Logs / VPC Flow / IAM**
* **Firewall Logs:** Palo Alto, Fortinet, Cisco ASA
* **IDS/IPS:** Suricata, Zeek, Snort
* **EDR logs**
* **NetFlow / DNS / VPN / Proxy logs**
* **Generic Network Logs**

---

# ğŸ§  NLP + Entity Extraction

### âœ” Extract usernames, IPs, hosts, processes

### âœ” Regex-based fast extraction

### âœ” Lightweight fallback-NER for missing usernames

### âœ” Sentence-transformer embeddings (MiniLM) for semantic analysis

Embeddings are generated **locally**, fully offline.

---

# ğŸ“Š Feature Engineering

The feature layer adds:

* Time features (hour, weekend, working-hours, weekday)
* IP rarity, private/public classification
* User rarity & behavior profiling
* Host behavior profiling
* Process grouping
* Aggregated behavioral metrics:

  * `user_failed_ratio`
  * `user_unique_ips`
  * `host_unique_ips`
  * `src_ip_failed_ratio`
  * `src_ip_unique_users`

Plus optional deep embeddings from NLP.

---

# ğŸ”¥ Machine Learning Support

Plugs into:

* **Isolation Forest**
* **Local Outlier Factor**
* **Autoencoders**
* **Sequence Models**
* **Risk Scoring Engines**

---

# ğŸ“¦ Project Structure

```
ML-UEBA/
â”‚
â”œâ”€â”€ preprocess/                 # Log parsing, normalization, missing handler
â”œâ”€â”€ nlp/                        # NLP pipeline, regex NER, username NER, embeddings
â”‚   â””â”€â”€ embeddings/             # MiniLM embeddings (local)
â”œâ”€â”€ features/                   # Feature engineering (encoders, aggregators)
â”œâ”€â”€ config/                     # Parser detection configuration
â”œâ”€â”€ data/                       # Raw & processed logs
â”œâ”€â”€ ml/                         # (optional) anomaly models
â”œâ”€â”€ test.py                     # Run full pipeline on local sample logs
â””â”€â”€ README.md
```

---

# ğŸ›  Installation Guide (uv)

This project uses **uv** â€” a fast Python package and environment manager.

---

## 1ï¸âƒ£ Install uv

```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

Verify:

```powershell
uv --version
```

---

## 2ï¸âƒ£ Create Project Environment

From project root:

```powershell
uv venv
```

Activate automatically:

```powershell
uv venv --python 3.10

uv run python --version
```

---

## 3ï¸âƒ£ Install Dependencies

```powershell
uv sync
```

Or manually:

```powershell
uv add pandas numpy pyyaml sentence-transformers scikit-learn
uv add accelerate==0.26.1 transformers
uv pip install torch --index-url https://download.pytorch.org/whl/cpu
```

This avoids compatibility issues.

---

## 4ï¸âƒ£ Install Local MiniLM Embedding Model

```powershell
uv run python nlp/embeddings/local_model_setup.py
```

This downloads:

```
nlp/embeddings/model/all-MiniLM-L6-v2/
```

Fully offline embedding support.

---

# â–¶ï¸ Running the Pipeline

Put logs here:

```bash
data/raw/sample.log
```

Then run:

```powershell
uv run test.py
```

This will:

* Auto-detect log type
* Parse & normalize
* NLP enrich
* Generate MiniLM embeddings
* Compute features
* Save CSV output

---

# ğŸ“˜ Folder-level READMEs

Each major folder contains its own README:

* `preprocess/README.md`
* `nlp/README.md`
* `features/README.md`
* `nlp/embeddings/README.md`
* `config/README.md`

---

# ğŸ¯ Summary

ML-UEBA is a complete, modular, offline-capable system for:

* Parsing all major log types
* Extracting entities
* Generating embeddings
* Performing UEBA
* Running ML anomaly detection

This makes it suitable for security automation, SIEM augmentation, and academic experimentation.

---

# ğŸŒ Web Interface & Agentic AI API

ML-UEBA includes a modern **Control Plane** with an **Agentic AI Consultant** for interactive threat hunting.

### 1ï¸âƒ£ Install Web Dependencies

The backend requires **FastAPI** to serve the UI and handle API requests.

```powershell
uv add fastapi uvicorn
```
*(Or `pip install fastapi uvicorn`)*

### 2ï¸âƒ£ Start the Server

Run the unified backend server (serves both Frontend and API):

```powershell
python server.py
# or
uv run python server.py
```

The server will start at: **[http://localhost:8000](http://localhost:8000)**

### 3ï¸âƒ£ Using the Agentic AI

1.  Navigate to the **Agentic AI** panel in the sidebar.
2.  Select context sources (PostgreSQL, ML Outputs, etc.).
3.  Type a query (e.g., *"Why is this IP anomalous?"*).
4.  The request flows to the backend API:
    *   **Endpoint:** `POST /api/agent/chat`
    *   **Payload:** `{ query: "...", context: { ... } }`

*Note: The current backend implementation (`server.py`) provides intelligent mock responses for demonstration. Connect it to a real LLM by modifying `chat_endpoint` in `server.py`.*




Perfect â€” below are **clean, readable, ASCII-only architectural diagrams** that you can paste directly into:

- README files
- Docs
- Terminal
- GitHub Markdown

Iâ€™ll give you **two diagrams**:

1ï¸âƒ£ **System Architecture (static view)**

2ï¸âƒ£ **End-to-End Workflow (runtime / data flow)**

Both are aligned exactly with your current ML-UEBA design.

---

## 1ï¸âƒ£ ML-UEBA â€” SYSTEM ARCHITECTURE (ASCII)

```
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚        FRONTEND          â”‚
                           â”‚  (HTML / CSS / JS)       â”‚
                           â”‚                          â”‚
                           â”‚  - Upload logs           â”‚
                           â”‚  - Configure pipeline    â”‚
                           â”‚  - Start / Stop run      â”‚
                           â”‚  - View metrics          â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚ HTTP (REST API)
                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          BACKEND (FastAPI)                      â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ API Layer     â”‚â”€â”€â–¶â”‚ Pipeline Runner  â”‚â”€â”€â–¶â”‚ Orchestrator â”‚  â”‚
â”‚  â”‚ (/api/*)      â”‚   â”‚ (control loop)   â”‚   â”‚ (stages)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   PROCESSING PIPELINE                    â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  Input â†’ Preprocess â†’ NLP â†’ Features â†’ ML â†’ Storage     â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Log Buffer (memory) â”‚    â”‚ PostgreSQL Writer             â”‚ â”‚
â”‚  â”‚ (UI logs)           â”‚    â”‚ (events table)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚         POSTGRESQL DB            â”‚
                         â”‚                                 â”‚
                         â”‚  - events                       â”‚
                         â”‚  - anomaly scores               â”‚
                         â”‚  - drift flags                  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚               GRAFANA                  â”‚
                     â”‚        (Dashboards / Visualization)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚               ADMINER                  â”‚
                     â”‚        (DB inspection / debug)         â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## 2ï¸âƒ£ ML-UEBA â€” DATA & WORKFLOW PIPELINE (ASCII)

This shows **what happens when the user clicks â€œSTARTâ€**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User uploads logs    â”‚
â”‚ + config via UI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend API receives â”‚
â”‚ input + settings     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PipelineRunner       â”‚
â”‚ starts loop          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Reader         â”‚
â”‚ (file / http / etc.) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ raw logs
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PREPROCESSING               â”‚
â”‚                            â”‚
â”‚ - Detect log type           â”‚
â”‚ - Parse fields              â”‚
â”‚ - Normalize schema          â”‚
â”‚ - Standardize timestamps    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ DataFrame
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NLP ENRICHMENT              â”‚
â”‚                            â”‚
â”‚ - Regex entity extraction   â”‚
â”‚ - Username recovery         â”‚
â”‚ - Message embeddings        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ df + embeddings
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FEATURE ENGINEERING         â”‚
â”‚                            â”‚
â”‚ - Time features             â”‚
â”‚ - Frequencies               â”‚
â”‚ - Rarity detection          â”‚
â”‚ - User / Host / IP aggs     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ feature matrix
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MACHINE LEARNING             â”‚
â”‚                              â”‚
â”‚ - Isolation Forest           â”‚
â”‚ - LSTM Autoencoder           â”‚
â”‚ - Ensemble anomaly score     â”‚
â”‚ - Page-Hinkley drift         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ enriched df
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORAGE                     â”‚
â”‚                            â”‚
â”‚ - Write to PostgreSQL       â”‚
â”‚ - Append logs to buffer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VISUALIZATION               â”‚
â”‚                            â”‚
â”‚ - Grafana dashboards        â”‚
â”‚ - Frontend metrics polling  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## 3ï¸âƒ£ RESPONSIBILITY BOUNDARIES (VERY IMPORTANT)

```
Frontend
  â””â”€â”€ UI / Control only
      (NO ML, NO parsing)

Backend
  â””â”€â”€ Orchestration & APIs
      (NO heavy logic inside routes)

Preprocess / NLP / Features / ML
  â””â”€â”€ Pure computation
      (Stateless, reusable, testable)

Storage
  â””â”€â”€ Persistence only
      (No business logic)

```

---

## 4ï¸âƒ£ WHY THIS ARCHITECTURE IS SOLID

âœ” Clear separation of concerns

âœ” Easy to test each block independently

âœ” Scales from file â†’ streaming inputs

âœ” Supports UEBA use-cases naturally

âœ” No LLM dependency

âœ” Production-ready structure

---

If you want next, I can:

- Convert this into **Mermaid diagrams**
- Create a **sequence diagram per API**
- Draw a **Kafka-based future extension**
- Make a **SOC analyst flow diagram**

Just tell me ğŸ‘



![arc.svg](attachment:561e2052-ddcb-4f97-97b0-6c527d8c42f4:arc.svg)
